import os
import time
import requests
from urllib.parse import urlparse
from log import log_info, log_error, log_warning
from utils import verify_hash_from_cdn_path, build_media_url
from media_utils import is_valid_video, is_valid_image

CDN_NODES = ["n1", "n2", "n3", "n4"]

def generate_alternative_urls(original_url):
    parsed = urlparse(original_url)
    path = parsed.path
    base = "coomer.st"
    urls = [f"https://{base}{path}"]
    for node in CDN_NODES:
        urls.append(f"https://{node}.{base}{path}")
    return urls

def download_file(url, final_path, on_progress=None, resume=True, retry_delay=10, should_stop=None, window_id=None):
    tmp_path = final_path if final_path.endswith(".tmp") else final_path + ".tmp"
    all_urls = generate_alternative_urls(url)
    log_prefix = f"[DL] [Window {window_id}]" if window_id else "[DL]"
    log_info(f"{log_prefix} ‚ñ∂Ô∏è D√©but t√©l√©chargement pour {final_path} depuis {url}")
    last_progress_update = 0
    min_progress_interval = 0.1
    session = requests.Session()

    for candidate_url in all_urls:
        log_info(f"{log_prefix} üåê Test CDN : {candidate_url}")

        retries = 0
        max_retries = 3
        while retries < max_retries:
            if should_stop and should_stop():
                log_info(f"{log_prefix} ‚õî T√©l√©chargement interrompu avant d√©marrage de {candidate_url}")
                session.close()
                return False, "Stopped"

            headers = {}
            mode = "wb"
            downloaded = 0

            if resume and os.path.exists(tmp_path):
                downloaded = os.path.getsize(tmp_path)
                headers["Range"] = f"bytes={downloaded}-"
                mode = "ab"
                log_info(f"{log_prefix} üîÑ Reprise √† {downloaded} bytes")

            try:
                log_info(f"{log_prefix} üì° Connexion au serveur pour {candidate_url}")
                with session.get(candidate_url, headers=headers, stream=True, timeout=(10, 30)) as r:
                    r.raise_for_status()
                    total = int(r.headers.get("Content-Length", 0)) + downloaded if r.headers.get("Content-Length") else 0
                    log_info(f"{log_prefix} üì¶ Taille attendue : {total} bytes")

                    with open(tmp_path, mode) as f:
                        chunk_count = 0
                        last_chunk_time = time.time()
                        last_downloaded = downloaded
                        last_time = time.time()

                        for chunk in r.iter_content(chunk_size=8192):
                            chunk_count += 1
                            if should_stop and should_stop():
                                log_info(f"{log_prefix} ‚õî Interruption pendant le chunk {chunk_count} pour {tmp_path}")
                                session.close()
                                return False, "Stopped"
                            if chunk:
                                f.write(chunk)
                                downloaded += len(chunk)
                                current_time = time.time()

                                time_diff = current_time - last_time
                                if time_diff > 0.01:
                                    speed = (downloaded - last_downloaded) / time_diff
                                    speed_str = (
                                        f"{speed:.1f} B/s" if speed < 1024 else
                                        f"{speed/1024:.1f} KB/s" if speed < 1024*1024 else
                                        f"{speed/(1024*1024):.1f} MB/s"
                                    )
                                    log_info(f"{log_prefix} üì• Re√ßu chunk {chunk_count} ({len(chunk)} bytes), total t√©l√©charg√© : {downloaded}/{total}, vitesse : {speed_str}")
                                else:
                                    speed_str = "0 B/s"

                                last_downloaded = downloaded
                                last_time = current_time
                                last_chunk_time = current_time

                                if on_progress and (current_time - last_progress_update >= min_progress_interval):
                                    try:
                                        last_progress_update = current_time
                                        on_progress(downloaded, speed_str, total)
                                    except Exception as e:
                                        log_info(f"{log_prefix} üö´ Erreur dans on_progress pour {tmp_path} : {e}")

                            if time.time() - last_chunk_time > 30:
                                raise Exception("Aucun chunk re√ßu pendant 30 secondes")

                    if not os.path.exists(tmp_path):
                        raise Exception("Fichier .tmp manquant apr√®s t√©l√©chargement")

                    real_size = os.path.getsize(tmp_path)
                    log_info(f"{log_prefix} üìè Taille r√©elle : {real_size} bytes (attendu : {total} bytes)")

                    if total > 0 and real_size < total * 0.95:
                        log_warning(f"{log_prefix} ‚è≥ Incomplet ({real_size}/{total}, {(real_size/total)*100:.1f}%) ‚Üí retry")
                        retries += 1
                        time.sleep(retry_delay)
                        continue

                    if not verify_hash_from_cdn_path(tmp_path, url):
                        log_warning(f"{log_prefix} ‚ùå Checksum invalide ‚Üí retry")
                        retries += 1
                        time.sleep(retry_delay)
                        continue

                    if final_path.endswith((".mp4", ".webm", ".mkv")) and not is_valid_video(tmp_path):
                        log_warning(f"{log_prefix} ‚ùå Vid√©o invalide ‚Üí retry")
                        retries += 1
                        time.sleep(retry_delay)
                        continue
                    if final_path.endswith((".jpg", ".png", ".webp", ".jpeg")) and not is_valid_image(tmp_path):
                        log_warning(f"{log_prefix} ‚ùå Image invalide ‚Üí retry")
                        retries += 1
                        time.sleep(retry_delay)
                        continue

                    # ‚úÖ Renommage s√©curis√©
                    if not os.path.exists(tmp_path):
                        raise Exception("Fichier .tmp manquant juste avant renommage")

                    try:
                        os.rename(tmp_path, final_path)
                    except FileNotFoundError as e:
                        raise Exception(f"√âchec renommage : {e}")

                    if not os.path.exists(final_path):
                        raise Exception("Fichier final non trouv√© apr√®s renommage")

                    log_info(f"{log_prefix} ‚úÖ T√©l√©chargement termin√© pour {final_path}")

                    if on_progress:
                        try:
                            on_progress(real_size, "0 B/s", real_size)
                            log_info(f"{log_prefix} üì¢ Mise √† jour finale √† 100% pour {final_path}")
                        except Exception as e:
                            log_info(f"{log_prefix} üö´ Erreur dans on_progress final pour {final_path} : {e}")

                    session.close()
                    return True, None

            except requests.exceptions.RequestException as e:
                retries += 1
                log_warning(f"{log_prefix} ‚ö†Ô∏è Erreur r√©seau (tentative {retries}/{max_retries}) : {e} ‚Üí retry dans {retry_delay}s")
                time.sleep(retry_delay)
            except Exception as e:
                retries += 1
                log_warning(f"{log_prefix} ‚ö†Ô∏è Exception (tentative {retries}/{max_retries}) : {e} ‚Üí retry dans {retry_delay}s")
                time.sleep(retry_delay)

        log_error(f"{log_prefix} üíÄ √âchec complet pour : {url}")
        session.close()
        return False, "√âchec complet sur tous les CDN"
